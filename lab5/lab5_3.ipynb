{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Rdu_jhdaDFd"
      },
      "outputs": [],
      "source": [
        "!cp -r ./drive/MyDrive/BERT-Relation-Extraction/ ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd BERT-Relation-Extraction/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "532IVPLVdu1Q",
        "outputId": "ff4af5f9-ec0c-47cf-aa69-4f77b2141ebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BERT-Relation-Extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_VxB5nPdzck",
        "outputId": "fdd20dcf-c9d1-4486-c95d-489c194b70fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: blis in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Collecting boto3 (from -r requirements.txt (line 2))\n",
            "  Downloading boto3-1.37.24-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore (from -r requirements.txt (line 3))\n",
            "  Downloading botocore-1.37.24-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: contourpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: cymem in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.0.11)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.56.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.5.2)\n",
            "Collecting jmespath (from -r requirements.txt (line 12))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: murmurhash in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (1.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (11.1.0)\n",
            "Collecting plac (from -r requirements.txt (line 21))\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: preshed in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (3.0.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (2.32.3)\n",
            "Collecting s3transfer (from -r requirements.txt (line 27))\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (1.14.1)\n",
            "Collecting seqeval (from -r requirements.txt (line 30))\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (1.17.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (3.8.4)\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (2.5.1)\n",
            "Requirement already satisfied: thinc in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (8.3.4)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (4.67.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (2025.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (2.3.0)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (1.1.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (3.21.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 32)) (3.5.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc->-r requirements.txt (line 34)) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 36))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 36)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 36)) (1.3.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 32)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 32)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 32)) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 32)) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 32)) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 32)) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->-r requirements.txt (line 32)) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 32)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 32)) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 32)) (0.1.2)\n",
            "Downloading boto3-1.37.24-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.24-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=2f81edb769a7edf6074866d53f36862817e9d5016e0c0ece021aba6873207b37\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: plac, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, seqeval, s3transfer, nvidia-cusolver-cu12, boto3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed boto3-1.37.24 botocore-1.37.24 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 plac-1.4.3 s3transfer-0.11.4 seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWIkFHilfO-W",
        "outputId": "f8098921-9b57-4a32-c935-e0839b615e44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSJ9Uti3fTZx",
        "outputId": "dae43cb9-a704-4b1a-8738-e1fe610d65fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "zyBbWqlAf89I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_task.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKTjgqvugGrD",
        "outputId": "a8d535a6-6c5b-4980-cd1c-edd28f7111e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04/01/2025 08:53:50 AM [INFO]: PyTorch version 2.6.0+cu124 available.\n",
            "2025-04-01 08:53:50.604523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743497630.625174    8677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743497630.631467    8677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-01 08:53:50.653763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/01/2025 08:53:53 AM [INFO]: TensorFlow version 2.18.0 available.\n",
            "04/01/2025 08:53:53 AM [INFO]: Loaded tokenizer from pre-trained blanks model\n",
            "04/01/2025 08:53:53 AM [INFO]: Reading training file ./data/SemEval2010_task8_all_data/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT...\n",
            "04/01/2025 08:53:53 AM [INFO]: Reading test file ./data/SemEval2010_task8_all_data/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT...\n",
            "04/01/2025 08:53:53 AM [INFO]: Mapping relations to IDs...\n",
            "100% 8000/8000 [00:00<00:00, 1674122.24it/s]\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 116382.32it/s]\n",
            "prog-bar: 100% 8000/8000 [00:00<00:00, 125799.24it/s]\n",
            "04/01/2025 08:53:53 AM [INFO]: Finished and saved!\n",
            "04/01/2025 08:53:53 AM [INFO]: Tokenizing data...\n",
            "prog-bar: 100% 8000/8000 [00:01<00:00, 4149.32it/s]\n",
            "prog-bar: 100% 8000/8000 [00:00<00:00, 79467.68it/s]\n",
            "\n",
            "Invalid rows/total: 0/8000\n",
            "04/01/2025 08:53:55 AM [INFO]: Tokenizing data...\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 6231.48it/s]\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 125172.16it/s]\n",
            "\n",
            "Invalid rows/total: 0/2717\n",
            "04/01/2025 08:53:55 AM [INFO]: Loaded 8000 Training samples.\n",
            "04/01/2025 08:53:56 AM [INFO]: https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_jaka5o6\n",
            "Downloading: 100% 684/684 [00:00<00:00, 3.38MB/s]\n",
            "04/01/2025 08:53:56 AM [INFO]: storing https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json in cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 08:53:56 AM [INFO]: creating metadata file for /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 08:53:56 AM [INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 08:53:56 AM [INFO]: Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"do_sample\": false,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "04/01/2025 08:53:56 AM [INFO]: https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpayqw932y\n",
            "Downloading: 100% 47.4M/47.4M [00:01<00:00, 28.7MB/s]\n",
            "04/01/2025 08:53:58 AM [INFO]: storing https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin in cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 08:53:58 AM [INFO]: creating metadata file for /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 08:53:58 AM [INFO]: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 08:53:59 AM [INFO]: Weights of AlbertModel not initialized from pretrained model: ['albert.classification_layer.weight', 'albert.classification_layer.bias']\n",
            "04/01/2025 08:53:59 AM [INFO]: FREEZING MOST HIDDEN LAYERS...\n",
            "[FROZE]: embeddings.word_embeddings.weight\n",
            "[FROZE]: embeddings.position_embeddings.weight\n",
            "[FROZE]: embeddings.token_type_embeddings.weight\n",
            "[FROZE]: embeddings.LayerNorm.weight\n",
            "[FROZE]: embeddings.LayerNorm.bias\n",
            "[FROZE]: encoder.embedding_hidden_mapping_in.weight\n",
            "[FROZE]: encoder.embedding_hidden_mapping_in.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn.weight\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn.bias\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias\n",
            "[FREE]: pooler.weight\n",
            "[FREE]: pooler.bias\n",
            "[FREE]: classification_layer.weight\n",
            "[FREE]: classification_layer.bias\n",
            "04/01/2025 08:54:04 AM [INFO]: Starting training process...\n",
            " 10% 24/250 [00:08<01:00,  3.75it/s][Epoch: 1,   800/ 8000 points] total loss, accuracy per batch: 2.620, 0.179\n",
            " 20% 49/250 [00:16<01:08,  2.93it/s][Epoch: 1,  1600/ 8000 points] total loss, accuracy per batch: 2.063, 0.396\n",
            " 30% 74/250 [00:24<00:52,  3.37it/s][Epoch: 1,  2400/ 8000 points] total loss, accuracy per batch: 1.424, 0.603\n",
            " 40% 99/250 [00:32<00:48,  3.14it/s][Epoch: 1,  3200/ 8000 points] total loss, accuracy per batch: 1.173, 0.660\n",
            " 50% 124/250 [00:40<00:37,  3.33it/s][Epoch: 1,  4000/ 8000 points] total loss, accuracy per batch: 1.041, 0.689\n",
            " 60% 149/250 [00:48<00:32,  3.12it/s][Epoch: 1,  4800/ 8000 points] total loss, accuracy per batch: 0.940, 0.700\n",
            " 70% 174/250 [00:56<00:22,  3.34it/s][Epoch: 1,  5600/ 8000 points] total loss, accuracy per batch: 0.852, 0.734\n",
            " 80% 199/250 [01:04<00:16,  3.16it/s][Epoch: 1,  6400/ 8000 points] total loss, accuracy per batch: 0.856, 0.718\n",
            " 90% 224/250 [01:11<00:08,  3.12it/s][Epoch: 1,  7200/ 8000 points] total loss, accuracy per batch: 0.951, 0.723\n",
            "100% 249/250 [01:21<00:00,  2.90it/s][Epoch: 1,  8000/ 8000 points] total loss, accuracy per batch: 0.871, 0.713\n",
            "100% 250/250 [01:21<00:00,  3.06it/s]\n",
            "04/01/2025 08:55:25 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.96it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "04/01/2025 08:55:38 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 08:55:38 AM [INFO]:   accuracy = 0.7310978701825558\n",
            "04/01/2025 08:55:38 AM [INFO]:   f1 = 0.6778947368421053\n",
            "04/01/2025 08:55:38 AM [INFO]:   precision = 0.729827742520399\n",
            "04/01/2025 08:55:38 AM [INFO]:   recall = 0.6328616352201258\n",
            "Epoch finished, took 93.88 seconds.\n",
            "Losses at Epoch 1: 1.2791858\n",
            "Train accuracy at Epoch 1: 0.6112500\n",
            "Test f1 at Epoch 1: 0.6778947\n",
            " 10% 24/250 [00:08<01:17,  2.90it/s][Epoch: 2,   800/ 8000 points] total loss, accuracy per batch: 0.718, 0.777\n",
            " 20% 49/250 [00:17<01:10,  2.85it/s][Epoch: 2,  1600/ 8000 points] total loss, accuracy per batch: 0.708, 0.780\n",
            " 30% 74/250 [00:26<00:56,  3.09it/s][Epoch: 2,  2400/ 8000 points] total loss, accuracy per batch: 0.694, 0.767\n",
            " 40% 99/250 [00:35<01:00,  2.49it/s][Epoch: 2,  3200/ 8000 points] total loss, accuracy per batch: 0.722, 0.770\n",
            " 50% 124/250 [00:44<00:43,  2.87it/s][Epoch: 2,  4000/ 8000 points] total loss, accuracy per batch: 0.710, 0.769\n",
            " 60% 149/250 [00:52<00:31,  3.22it/s][Epoch: 2,  4800/ 8000 points] total loss, accuracy per batch: 0.642, 0.792\n",
            " 70% 174/250 [01:00<00:25,  3.00it/s][Epoch: 2,  5600/ 8000 points] total loss, accuracy per batch: 0.668, 0.787\n",
            " 80% 199/250 [01:09<00:18,  2.83it/s][Epoch: 2,  6400/ 8000 points] total loss, accuracy per batch: 0.697, 0.774\n",
            " 90% 224/250 [01:17<00:08,  3.11it/s][Epoch: 2,  7200/ 8000 points] total loss, accuracy per batch: 0.638, 0.787\n",
            "100% 249/250 [01:25<00:00,  3.09it/s][Epoch: 2,  8000/ 8000 points] total loss, accuracy per batch: 0.613, 0.804\n",
            "100% 250/250 [01:25<00:00,  2.91it/s]\n",
            "04/01/2025 08:57:04 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.91it/s]\n",
            "04/01/2025 08:57:16 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 08:57:16 AM [INFO]:   accuracy = 0.7917216024340771\n",
            "04/01/2025 08:57:16 AM [INFO]:   f1 = 0.7640094711917916\n",
            "04/01/2025 08:57:16 AM [INFO]:   precision = 0.7744\n",
            "04/01/2025 08:57:16 AM [INFO]:   recall = 0.7538940809968847\n",
            "Epoch finished, took 98.12 seconds.\n",
            "Losses at Epoch 2: 0.6809917\n",
            "Train accuracy at Epoch 2: 0.7808750\n",
            "Test f1 at Epoch 2: 0.7640095\n",
            " 10% 24/250 [00:08<01:40,  2.25it/s][Epoch: 3,   800/ 8000 points] total loss, accuracy per batch: 0.510, 0.843\n",
            " 20% 49/250 [00:17<01:22,  2.44it/s][Epoch: 3,  1600/ 8000 points] total loss, accuracy per batch: 0.446, 0.853\n",
            " 30% 74/250 [00:25<00:54,  3.24it/s][Epoch: 3,  2400/ 8000 points] total loss, accuracy per batch: 0.428, 0.864\n",
            " 40% 99/250 [00:34<00:59,  2.53it/s][Epoch: 3,  3200/ 8000 points] total loss, accuracy per batch: 0.517, 0.831\n",
            " 50% 124/250 [00:42<00:40,  3.09it/s][Epoch: 3,  4000/ 8000 points] total loss, accuracy per batch: 0.436, 0.859\n",
            " 60% 149/250 [00:51<00:38,  2.60it/s][Epoch: 3,  4800/ 8000 points] total loss, accuracy per batch: 0.515, 0.834\n",
            " 70% 174/250 [00:59<00:25,  2.99it/s][Epoch: 3,  5600/ 8000 points] total loss, accuracy per batch: 0.472, 0.861\n",
            " 80% 199/250 [01:07<00:14,  3.46it/s][Epoch: 3,  6400/ 8000 points] total loss, accuracy per batch: 0.552, 0.828\n",
            " 90% 224/250 [01:16<00:08,  3.00it/s][Epoch: 3,  7200/ 8000 points] total loss, accuracy per batch: 0.525, 0.826\n",
            "100% 249/250 [01:25<00:00,  2.67it/s][Epoch: 3,  8000/ 8000 points] total loss, accuracy per batch: 0.447, 0.861\n",
            "100% 250/250 [01:25<00:00,  2.92it/s]\n",
            "04/01/2025 08:58:42 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.82it/s]\n",
            "04/01/2025 08:58:55 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 08:58:55 AM [INFO]:   accuracy = 0.8027129817444218\n",
            "04/01/2025 08:58:55 AM [INFO]:   f1 = 0.7572815533980582\n",
            "04/01/2025 08:58:55 AM [INFO]:   precision = 0.7523148148148148\n",
            "04/01/2025 08:58:55 AM [INFO]:   recall = 0.7623143080531666\n",
            "Epoch finished, took 98.02 seconds.\n",
            "Losses at Epoch 3: 0.4845872\n",
            "Train accuracy at Epoch 3: 0.8458750\n",
            "Test f1 at Epoch 3: 0.7572816\n",
            "04/01/2025 08:58:55 AM [INFO]: Finished Training!\n",
            "04/01/2025 08:58:58 AM [INFO]: Loading tokenizer and model...\n",
            "04/01/2025 08:58:59 AM [INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 08:58:59 AM [INFO]: Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"do_sample\": false,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "04/01/2025 08:58:59 AM [INFO]: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 08:58:59 AM [INFO]: Weights of AlbertModel not initialized from pretrained model: ['albert.classification_layer.weight', 'albert.classification_layer.bias']\n",
            "04/01/2025 08:58:59 AM [INFO]: Loaded checkpoint model.\n",
            "04/01/2025 08:58:59 AM [INFO]: Loaded model and optimizer.\n",
            "04/01/2025 08:58:59 AM [INFO]: Done!\n",
            "Sentence:  The surprise [E1]visit[/E1] caused a [E2]frenzy[/E2] on the already chaotic trading floor.\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Sentence:  [E2]After eating the chicken[/E2] , [E1]he[/E1] developed a sore throat the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Sentence:  After eating the chicken , [E1]he[/E1] developed [E2]a sore throat[/E2] the next morning .\n",
            "Predicted:  Product-Producer(e2,e1) \n",
            "\n",
            "Sentence:  [E1]After eating the chicken[/E1] , [E2]he[/E2] developed a sore throat the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Sentence:  [E1]After eating the chicken[/E1] , he developed [E2]a sore throat[/E2] the next morning .\n",
            "Predicted:  Product-Producer(e2,e1) \n",
            "\n",
            "Sentence:  After eating the chicken , [E2]he[/E2] developed [E1]a sore throat[/E1] the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Sentence:  [E2]After eating the chicken[/E2] , he developed [E1]a sore throat[/E1] the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Type input sentence ('quit' or 'exit' to terminate):\n",
            "object address  : 0x7fcbf61b5840\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_task.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Li7n3-AnfNg",
        "outputId": "48a5fe1e-dfcc-4ed3-c498-1a7316c682c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04/01/2025 09:27:04 AM [INFO]: PyTorch version 2.6.0+cu124 available.\n",
            "2025-04-01 09:27:04.600791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743499624.623397   17263 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743499624.629939   17263 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-01 09:27:04.651323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/01/2025 09:27:06 AM [INFO]: TensorFlow version 2.18.0 available.\n",
            "04/01/2025 09:27:06 AM [INFO]: Pre-trained blanks tokenizer not found, initializing new tokenizer...\n",
            "04/01/2025 09:27:07 AM [INFO]: loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
            "04/01/2025 09:27:07 AM [INFO]: Adding [E1] to the vocabulary\n",
            "04/01/2025 09:27:07 AM [INFO]: Adding [/E1] to the vocabulary\n",
            "04/01/2025 09:27:07 AM [INFO]: Adding [E2] to the vocabulary\n",
            "04/01/2025 09:27:07 AM [INFO]: Adding [/E2] to the vocabulary\n",
            "04/01/2025 09:27:07 AM [INFO]: Adding [BLANK] to the vocabulary\n",
            "04/01/2025 09:27:07 AM [INFO]: Saved ALBERT tokenizer at ./data/ALBERT_tokenizer.pkl\n",
            "04/01/2025 09:27:07 AM [INFO]: Reading training file ./data/SemEval2010_task8_all_data/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT...\n",
            "04/01/2025 09:27:07 AM [INFO]: Reading test file ./data/SemEval2010_task8_all_data/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT...\n",
            "04/01/2025 09:27:07 AM [INFO]: Mapping relations to IDs...\n",
            "100% 8000/8000 [00:00<00:00, 2948803.23it/s]\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 230104.47it/s]\n",
            "prog-bar: 100% 8000/8000 [00:00<00:00, 239582.10it/s]\n",
            "04/01/2025 09:27:07 AM [INFO]: Finished and saved!\n",
            "04/01/2025 09:27:07 AM [INFO]: Tokenizing data...\n",
            "prog-bar: 100% 8000/8000 [00:01<00:00, 4402.76it/s]\n",
            "prog-bar: 100% 8000/8000 [00:00<00:00, 76324.43it/s]\n",
            "\n",
            "Invalid rows/total: 0/8000\n",
            "04/01/2025 09:27:09 AM [INFO]: Tokenizing data...\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 4627.50it/s]\n",
            "prog-bar: 100% 2717/2717 [00:00<00:00, 69881.49it/s]\n",
            "\n",
            "Invalid rows/total: 0/2717\n",
            "04/01/2025 09:27:09 AM [INFO]: Loaded 8000 Training samples.\n",
            "04/01/2025 09:27:10 AM [INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 09:27:10 AM [INFO]: Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"do_sample\": false,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "04/01/2025 09:27:10 AM [INFO]: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 09:27:10 AM [INFO]: Weights of AlbertModel not initialized from pretrained model: ['albert.classification_layer.weight', 'albert.classification_layer.bias']\n",
            "04/01/2025 09:27:11 AM [INFO]: FREEZING MOST HIDDEN LAYERS...\n",
            "[FROZE]: embeddings.word_embeddings.weight\n",
            "[FROZE]: embeddings.position_embeddings.weight\n",
            "[FROZE]: embeddings.token_type_embeddings.weight\n",
            "[FROZE]: embeddings.LayerNorm.weight\n",
            "[FROZE]: embeddings.LayerNorm.bias\n",
            "[FROZE]: encoder.embedding_hidden_mapping_in.weight\n",
            "[FROZE]: encoder.embedding_hidden_mapping_in.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight\n",
            "[FROZE]: encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn.weight\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn.bias\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight\n",
            "[FREE]: encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias\n",
            "[FREE]: pooler.weight\n",
            "[FREE]: pooler.bias\n",
            "[FREE]: classification_layer.weight\n",
            "[FREE]: classification_layer.bias\n",
            "04/01/2025 09:27:12 AM [INFO]: Starting training process...\n",
            " 10% 24/250 [00:07<01:04,  3.51it/s][Epoch: 1,   800/ 8000 points] total loss, accuracy per batch: 2.745, 0.165\n",
            " 20% 49/250 [00:15<00:54,  3.68it/s][Epoch: 1,  1600/ 8000 points] total loss, accuracy per batch: 2.404, 0.244\n",
            " 30% 74/250 [00:22<01:00,  2.93it/s][Epoch: 1,  2400/ 8000 points] total loss, accuracy per batch: 2.187, 0.306\n",
            " 40% 99/250 [00:30<00:49,  3.02it/s][Epoch: 1,  3200/ 8000 points] total loss, accuracy per batch: 1.952, 0.380\n",
            " 50% 124/250 [00:38<00:34,  3.61it/s][Epoch: 1,  4000/ 8000 points] total loss, accuracy per batch: 1.595, 0.512\n",
            " 60% 149/250 [00:46<00:33,  2.98it/s][Epoch: 1,  4800/ 8000 points] total loss, accuracy per batch: 1.368, 0.604\n",
            " 70% 174/250 [00:54<00:22,  3.33it/s][Epoch: 1,  5600/ 8000 points] total loss, accuracy per batch: 1.162, 0.657\n",
            " 80% 199/250 [01:02<00:17,  2.90it/s][Epoch: 1,  6400/ 8000 points] total loss, accuracy per batch: 1.110, 0.664\n",
            " 90% 224/250 [01:10<00:08,  3.06it/s][Epoch: 1,  7200/ 8000 points] total loss, accuracy per batch: 1.060, 0.684\n",
            "100% 249/250 [01:19<00:00,  2.99it/s][Epoch: 1,  8000/ 8000 points] total loss, accuracy per batch: 1.013, 0.669\n",
            "100% 250/250 [01:19<00:00,  3.15it/s]\n",
            "04/01/2025 09:28:31 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.58it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "04/01/2025 09:28:44 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 09:28:44 AM [INFO]:   accuracy = 0.7345081135902637\n",
            "04/01/2025 09:28:44 AM [INFO]:   f1 = 0.6627664020058504\n",
            "04/01/2025 09:28:44 AM [INFO]:   precision = 0.6925764192139738\n",
            "04/01/2025 09:28:44 AM [INFO]:   recall = 0.6354166666666666\n",
            "Epoch finished, took 92.32 seconds.\n",
            "Losses at Epoch 1: 1.6594625\n",
            "Train accuracy at Epoch 1: 0.4885000\n",
            "Test f1 at Epoch 1: 0.6627664\n",
            " 10% 24/250 [00:08<01:15,  2.99it/s][Epoch: 2,   800/ 8000 points] total loss, accuracy per batch: 0.837, 0.728\n",
            " 20% 49/250 [00:16<01:00,  3.31it/s][Epoch: 2,  1600/ 8000 points] total loss, accuracy per batch: 0.926, 0.720\n",
            " 30% 74/250 [00:24<00:52,  3.37it/s][Epoch: 2,  2400/ 8000 points] total loss, accuracy per batch: 0.794, 0.769\n",
            " 40% 99/250 [00:32<00:49,  3.08it/s][Epoch: 2,  3200/ 8000 points] total loss, accuracy per batch: 0.801, 0.766\n",
            " 50% 124/250 [00:41<00:44,  2.83it/s][Epoch: 2,  4000/ 8000 points] total loss, accuracy per batch: 0.852, 0.730\n",
            " 60% 149/250 [00:49<00:29,  3.47it/s][Epoch: 2,  4800/ 8000 points] total loss, accuracy per batch: 0.760, 0.775\n",
            " 70% 174/250 [00:57<00:27,  2.77it/s][Epoch: 2,  5600/ 8000 points] total loss, accuracy per batch: 0.702, 0.799\n",
            " 80% 199/250 [01:06<00:17,  3.00it/s][Epoch: 2,  6400/ 8000 points] total loss, accuracy per batch: 0.741, 0.766\n",
            " 90% 224/250 [01:15<00:09,  2.78it/s][Epoch: 2,  7200/ 8000 points] total loss, accuracy per batch: 0.795, 0.759\n",
            "100% 249/250 [01:24<00:00,  2.25it/s][Epoch: 2,  8000/ 8000 points] total loss, accuracy per batch: 0.774, 0.767\n",
            "100% 250/250 [01:24<00:00,  2.95it/s]\n",
            "04/01/2025 09:30:09 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.76it/s]\n",
            "04/01/2025 09:30:22 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 09:30:22 AM [INFO]:   accuracy = 0.7799568965517242\n",
            "04/01/2025 09:30:22 AM [INFO]:   f1 = 0.7110055423594616\n",
            "04/01/2025 09:30:22 AM [INFO]:   precision = 0.7121332275971451\n",
            "04/01/2025 09:30:22 AM [INFO]:   recall = 0.7098814229249012\n",
            "Epoch finished, took 97.35 seconds.\n",
            "Losses at Epoch 2: 0.7981035\n",
            "Train accuracy at Epoch 2: 0.7578750\n",
            "Test f1 at Epoch 2: 0.7110055\n",
            " 10% 24/250 [00:07<01:19,  2.85it/s][Epoch: 3,   800/ 8000 points] total loss, accuracy per batch: 0.524, 0.836\n",
            " 20% 49/250 [00:17<01:25,  2.35it/s][Epoch: 3,  1600/ 8000 points] total loss, accuracy per batch: 0.659, 0.789\n",
            " 30% 74/250 [00:25<00:53,  3.31it/s][Epoch: 3,  2400/ 8000 points] total loss, accuracy per batch: 0.704, 0.782\n",
            " 40% 99/250 [00:33<00:57,  2.63it/s][Epoch: 3,  3200/ 8000 points] total loss, accuracy per batch: 0.541, 0.833\n",
            " 50% 124/250 [00:42<00:44,  2.82it/s][Epoch: 3,  4000/ 8000 points] total loss, accuracy per batch: 0.590, 0.809\n",
            " 60% 149/250 [00:50<00:31,  3.21it/s][Epoch: 3,  4800/ 8000 points] total loss, accuracy per batch: 0.603, 0.811\n",
            " 70% 174/250 [00:58<00:21,  3.54it/s][Epoch: 3,  5600/ 8000 points] total loss, accuracy per batch: 0.604, 0.820\n",
            " 80% 199/250 [01:06<00:17,  2.85it/s][Epoch: 3,  6400/ 8000 points] total loss, accuracy per batch: 0.505, 0.853\n",
            " 90% 224/250 [01:15<00:09,  2.85it/s][Epoch: 3,  7200/ 8000 points] total loss, accuracy per batch: 0.533, 0.841\n",
            "100% 249/250 [01:24<00:00,  3.14it/s][Epoch: 3,  8000/ 8000 points] total loss, accuracy per batch: 0.653, 0.800\n",
            "100% 250/250 [01:24<00:00,  2.96it/s]\n",
            "04/01/2025 09:31:46 AM [INFO]: Evaluating test samples...\n",
            "100% 85/85 [00:12<00:00,  6.78it/s]\n",
            "04/01/2025 09:31:59 AM [INFO]: ***** Eval results *****\n",
            "04/01/2025 09:31:59 AM [INFO]:   accuracy = 0.7920131845841786\n",
            "04/01/2025 09:31:59 AM [INFO]:   f1 = 0.7720855183541752\n",
            "04/01/2025 09:31:59 AM [INFO]:   precision = 0.7844262295081967\n",
            "04/01/2025 09:31:59 AM [INFO]:   recall = 0.7601270849880858\n",
            "Epoch finished, took 96.99 seconds.\n",
            "Losses at Epoch 3: 0.5916487\n",
            "Train accuracy at Epoch 3: 0.8173750\n",
            "Test f1 at Epoch 3: 0.7720855\n",
            "04/01/2025 09:31:59 AM [INFO]: Finished Training!\n",
            "04/01/2025 09:32:02 AM [INFO]: Loading tokenizer and model...\n",
            "04/01/2025 09:32:02 AM [INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
            "04/01/2025 09:32:02 AM [INFO]: Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"do_sample\": false,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "04/01/2025 09:32:02 AM [INFO]: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "04/01/2025 09:32:03 AM [INFO]: Weights of AlbertModel not initialized from pretrained model: ['albert.classification_layer.weight', 'albert.classification_layer.bias']\n",
            "04/01/2025 09:32:03 AM [INFO]: Loaded checkpoint model.\n",
            "04/01/2025 09:32:03 AM [INFO]: Loaded model and optimizer.\n",
            "04/01/2025 09:32:03 AM [INFO]: Done!\n",
            "Sentence:  The surprise [E1]visit[/E1] caused a [E2]frenzy[/E2] on the already chaotic trading floor.\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Sentence:  [E2]After eating the chicken[/E2] , [E1]he[/E1] developed a sore throat the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Sentence:  After eating the chicken , [E1]he[/E1] developed [E2]a sore throat[/E2] the next morning .\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Sentence:  [E1]After eating the chicken[/E1] , [E2]he[/E2] developed a sore throat the next morning .\n",
            "Predicted:  Other \n",
            "\n",
            "Sentence:  [E1]After eating the chicken[/E1] , he developed [E2]a sore throat[/E2] the next morning .\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Sentence:  After eating the chicken , [E2]he[/E2] developed [E1]a sore throat[/E1] the next morning .\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Sentence:  [E2]After eating the chicken[/E2] , he developed [E1]a sore throat[/E1] the next morning .\n",
            "Predicted:  Cause-Effect(e1,e2) \n",
            "\n",
            "Type input sentence ('quit' or 'exit' to terminate):\n",
            "object address  : 0x78f762015840\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n"
          ]
        }
      ]
    }
  ]
}